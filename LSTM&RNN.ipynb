{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02c47dc-b388-42c4-a623-77ed8e90ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77075f30-16a7-4eaa-b701-f054852f1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-cleaned datasets\n",
    "df_train = pd.read_csv(\"sent_train.csv\")\n",
    "df_valid = pd.read_csv(\"sent_valid.csv\")\n",
    "\n",
    "train_texts = df_train['text'].tolist()\n",
    "train_labels = df_train['label'].tolist()\n",
    "\n",
    "val_texts = df_valid['text'].tolist()\n",
    "val_labels = df_valid['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b580bf7f-1a10-4f4d-915b-a4c9ad3c233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [text.split() for text in train_texts]\n",
    "word_counts = Counter(word for sentence in tokenized for word in sentence)\n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(word_counts.items())}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1\n",
    "\n",
    "def encode(text):\n",
    "    return [vocab.get(word, 1) for word in text.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e33aea-2c63-4735-b95f-cc66474d5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = [torch.tensor(encode(text)) for text in texts]\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    return padded, torch.tensor(labels)\n",
    "\n",
    "train_ds = SentimentDataset(train_texts, train_labels)\n",
    "val_ds = SentimentDataset(val_texts, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc035d1-20ae-4d4d-96d7-076326e50d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return out\n",
    "\n",
    "model = LSTMClassifier(vocab_size=len(vocab), embed_dim=100, hidden_dim=128, output_dim=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2afa044d-8237-44b7-a5c7-89db16973bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss = 0.9470, Val Acc = 0.5369\n",
      "Epoch 2: Val Loss = 0.8642, Val Acc = 0.5867\n",
      "Epoch 3: Val Loss = 1.1153, Val Acc = 0.5352\n",
      "Epoch 4: Val Loss = 1.0341, Val Acc = 0.5360\n",
      "Epoch 5: Val Loss = 1.4325, Val Acc = 0.5419\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x, y = [b.to(device) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, y = [b.to(device) for b in batch]\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            val_loss += loss.item() * y.size(0)\n",
    "            preds = output.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_acc = correct / total\n",
    "    val_loss /= total\n",
    "    print(f\"Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50a05fb-25b1-492a-a72e-216c9609f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.33      0.36      0.35       347\n",
      "     Bullish       0.31      0.72      0.44       475\n",
      "     Neutral       0.90      0.53      0.66      1566\n",
      "\n",
      "    accuracy                           0.54      2388\n",
      "   macro avg       0.52      0.54      0.48      2388\n",
      "weighted avg       0.70      0.54      0.57      2388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Evaluation on Validation Set:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Bearish\", \"Bullish\", \"Neutral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ccda2-c799-497d-86ea-551ffadafa77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
